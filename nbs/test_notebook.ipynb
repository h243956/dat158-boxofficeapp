{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame the problem\n",
    "Normally people can get the value of their house by contacting a housing agency, and or by looking at house prices in their area. In this notebook we will use historical data to predict housing prices in California. The historical data stems from a dataset from 1997 containing housing prices in California. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data\n",
    "The dataset is given as part of an exercise in the book \"Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow concepts, tools, and techniques to build intelligent systems\", 2019. The dataset is downloaded as a .tgz file through github which contains the dataset in a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     3000 non-null   int64  \n",
      " 1   belongs_to_collection  604 non-null    object \n",
      " 2   budget                 3000 non-null   int64  \n",
      " 3   genres                 2993 non-null   object \n",
      " 4   homepage               946 non-null    object \n",
      " 5   imdb_id                3000 non-null   object \n",
      " 6   original_language      3000 non-null   object \n",
      " 7   original_title         3000 non-null   object \n",
      " 8   overview               2992 non-null   object \n",
      " 9   popularity             3000 non-null   float64\n",
      " 10  poster_path            2999 non-null   object \n",
      " 11  production_companies   2844 non-null   object \n",
      " 12  production_countries   2945 non-null   object \n",
      " 13  release_date           3000 non-null   object \n",
      " 14  runtime                2998 non-null   float64\n",
      " 15  spoken_languages       2980 non-null   object \n",
      " 16  status                 3000 non-null   object \n",
      " 17  tagline                2403 non-null   object \n",
      " 18  title                  3000 non-null   object \n",
      " 19  Keywords               2724 non-null   object \n",
      " 20  cast                   2987 non-null   object \n",
      " 21  crew                   2984 non-null   object \n",
      " 22  revenue                3000 non-null   int64  \n",
      "dtypes: float64(2), int64(3), object(18)\n",
      "memory usage: 539.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "                   \n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data to gain insight\n",
    "Lets start off with getting an overview of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_og = test\n",
    "x_train_og = train\n",
    "\n",
    "x_train = x_train_og.drop(\"revenue\", axis=1)\n",
    "x_train_labels = x_train_og[\"revenue\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/kenne/DAT158ML/ML_2/boxofficeapp/localpackages\n",
      "Installing collected packages: localpackages\n",
      "  Attempting uninstall: localpackages\n",
      "    Found existing installation: localpackages 0.1\n",
      "    Uninstalling localpackages-0.1:\n",
      "      Successfully uninstalled localpackages-0.1\n",
      "  Running setup.py develop for localpackages\n",
      "Successfully installed localpackages\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "!{sys.executable} -m pip install -e ../localpackages\n",
    "from localpackages.custom_transformers.custom_transformers import SelectColumnsTransformer\n",
    "                \n",
    "columns = [\"id\", \"budget\", \"popularity\", \"runtime\"]\n",
    "\n",
    "data_cols_pipeline = make_pipeline(\n",
    "    SelectColumnsTransformer(columns),   \n",
    "    SimpleImputer(missing_values=np.nan, strategy=\"median\"),\n",
    "    SimpleImputer(missing_values=0, strategy=\"median\")\n",
    ")\n",
    "\n",
    "#preprocessing_features = DataFrameFeatureUnion([data_cols_pipeline, nullvalues_pipline])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>...</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'id': 313576, 'name': 'Hot Tub Time Machine ...</td>\n",
       "      <td>14000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt2637294</td>\n",
       "      <td>en</td>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>When Lou, who has become the \"father of the In...</td>\n",
       "      <td>6.575393</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>2/20/15</td>\n",
       "      <td>93.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Laws of Space and Time are About to be Vio...</td>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>[{'id': 4379, 'name': 'time travel'}, {'id': 9...</td>\n",
       "      <td>[{'cast_id': 4, 'character': 'Lou', 'credit_id...</td>\n",
       "      <td>[{'credit_id': '59ac067c92514107af02c8c8', 'de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[{'id': 107674, 'name': 'The Princess Diaries ...</td>\n",
       "      <td>40000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0368933</td>\n",
       "      <td>en</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>Mia Thermopolis is now a college graduate and ...</td>\n",
       "      <td>8.248895</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>8/6/04</td>\n",
       "      <td>113.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>It can take a lifetime to find true love; she'...</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>[{'id': 2505, 'name': 'coronation'}, {'id': 42...</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Mia Thermopolis'...</td>\n",
       "      <td>[{'credit_id': '52fe43fe9251416c7502563d', 'de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3300000</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
       "      <td>http://sonyclassics.com/whiplash/</td>\n",
       "      <td>tt2582802</td>\n",
       "      <td>en</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>Under the direction of a ruthless instructor, ...</td>\n",
       "      <td>64.299990</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>10/10/14</td>\n",
       "      <td>105.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The road to greatness can take you to the edge.</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>[{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...</td>\n",
       "      <td>[{'cast_id': 5, 'character': 'Andrew Neimann',...</td>\n",
       "      <td>[{'credit_id': '54d5356ec3a3683ba0000039', 'de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200000</td>\n",
       "      <td>[{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...</td>\n",
       "      <td>http://kahaanithefilm.com/</td>\n",
       "      <td>tt1821480</td>\n",
       "      <td>hi</td>\n",
       "      <td>Kahaani</td>\n",
       "      <td>Vidya Bagchi (Vidya Balan) arrives in Kolkata ...</td>\n",
       "      <td>3.174936</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'iso_3166_1': 'IN', 'name': 'India'}]</td>\n",
       "      <td>3/9/12</td>\n",
       "      <td>122.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kahaani</td>\n",
       "      <td>[{'id': 10092, 'name': 'mystery'}, {'id': 1054...</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Vidya Bagchi', '...</td>\n",
       "      <td>[{'credit_id': '52fe48779251416c9108d6eb', 'de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt1380152</td>\n",
       "      <td>ko</td>\n",
       "      <td>마린보이</td>\n",
       "      <td>Marine Boy is the story of a former national s...</td>\n",
       "      <td>1.148070</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'iso_3166_1': 'KR', 'name': 'South Korea'}]</td>\n",
       "      <td>2/5/09</td>\n",
       "      <td>118.0</td>\n",
       "      <td>[{'iso_639_1': 'ko', 'name': '한국어/조선말'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marine Boy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'cast_id': 3, 'character': 'Chun-soo', 'cred...</td>\n",
       "      <td>[{'credit_id': '52fe464b9251416c75073b43', 'de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                              belongs_to_collection    budget  \\\n",
       "0   1  [{'id': 313576, 'name': 'Hot Tub Time Machine ...  14000000   \n",
       "1   2  [{'id': 107674, 'name': 'The Princess Diaries ...  40000000   \n",
       "2   3                                                NaN   3300000   \n",
       "3   4                                                NaN   1200000   \n",
       "4   5                                                NaN         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "1  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "2                      [{'id': 18, 'name': 'Drama'}]   \n",
       "3  [{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...   \n",
       "4  [{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...   \n",
       "\n",
       "                            homepage    imdb_id original_language  \\\n",
       "0                                NaN  tt2637294                en   \n",
       "1                                NaN  tt0368933                en   \n",
       "2  http://sonyclassics.com/whiplash/  tt2582802                en   \n",
       "3         http://kahaanithefilm.com/  tt1821480                hi   \n",
       "4                                NaN  tt1380152                ko   \n",
       "\n",
       "                             original_title  \\\n",
       "0                    Hot Tub Time Machine 2   \n",
       "1  The Princess Diaries 2: Royal Engagement   \n",
       "2                                  Whiplash   \n",
       "3                                   Kahaani   \n",
       "4                                      마린보이   \n",
       "\n",
       "                                            overview  popularity  ...  \\\n",
       "0  When Lou, who has become the \"father of the In...    6.575393  ...   \n",
       "1  Mia Thermopolis is now a college graduate and ...    8.248895  ...   \n",
       "2  Under the direction of a ruthless instructor, ...   64.299990  ...   \n",
       "3  Vidya Bagchi (Vidya Balan) arrives in Kolkata ...    3.174936  ...   \n",
       "4  Marine Boy is the story of a former national s...    1.148070  ...   \n",
       "\n",
       "                                production_countries release_date runtime  \\\n",
       "0  [{'iso_3166_1': 'US', 'name': 'United States o...      2/20/15    93.0   \n",
       "1  [{'iso_3166_1': 'US', 'name': 'United States o...       8/6/04   113.0   \n",
       "2  [{'iso_3166_1': 'US', 'name': 'United States o...     10/10/14   105.0   \n",
       "3            [{'iso_3166_1': 'IN', 'name': 'India'}]       3/9/12   122.0   \n",
       "4      [{'iso_3166_1': 'KR', 'name': 'South Korea'}]       2/5/09   118.0   \n",
       "\n",
       "                                    spoken_languages    status  \\\n",
       "0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "1           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "2           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "3  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "4           [{'iso_639_1': 'ko', 'name': '한국어/조선말'}]  Released   \n",
       "\n",
       "                                             tagline  \\\n",
       "0  The Laws of Space and Time are About to be Vio...   \n",
       "1  It can take a lifetime to find true love; she'...   \n",
       "2    The road to greatness can take you to the edge.   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                      title  \\\n",
       "0                    Hot Tub Time Machine 2   \n",
       "1  The Princess Diaries 2: Royal Engagement   \n",
       "2                                  Whiplash   \n",
       "3                                   Kahaani   \n",
       "4                                Marine Boy   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  [{'id': 4379, 'name': 'time travel'}, {'id': 9...   \n",
       "1  [{'id': 2505, 'name': 'coronation'}, {'id': 42...   \n",
       "2  [{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...   \n",
       "3  [{'id': 10092, 'name': 'mystery'}, {'id': 1054...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                                cast  \\\n",
       "0  [{'cast_id': 4, 'character': 'Lou', 'credit_id...   \n",
       "1  [{'cast_id': 1, 'character': 'Mia Thermopolis'...   \n",
       "2  [{'cast_id': 5, 'character': 'Andrew Neimann',...   \n",
       "3  [{'cast_id': 1, 'character': 'Vidya Bagchi', '...   \n",
       "4  [{'cast_id': 3, 'character': 'Chun-soo', 'cred...   \n",
       "\n",
       "                                                crew  \n",
       "0  [{'credit_id': '59ac067c92514107af02c8c8', 'de...  \n",
       "1  [{'credit_id': '52fe43fe9251416c7502563d', 'de...  \n",
       "2  [{'credit_id': '54d5356ec3a3683ba0000039', 'de...  \n",
       "3  [{'credit_id': '52fe48779251416c9108d6eb', 'de...  \n",
       "4  [{'credit_id': '52fe464b9251416c75073b43', 'de...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_train=preprocessing_features.fit_transform(x_train)\n",
    "x_train_prepared=data_cols_pipeline.fit_transform(x_train)\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 1.4000000e+07 6.5753930e+00 9.3000000e+01]\n",
      " [2.0000000e+00 4.0000000e+07 8.2488950e+00 1.1300000e+02]\n",
      " [3.0000000e+00 3.3000000e+06 6.4299990e+01 1.0500000e+02]\n",
      " ...\n",
      " [2.9980000e+03 6.5000000e+07 1.4482345e+01 1.2000000e+02]\n",
      " [2.9990000e+03 4.2000000e+07 1.5725542e+01 9.0000000e+01]\n",
      " [3.0000000e+03 3.5000000e+07 1.0512109e+01 1.0600000e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore different models and short-list the best ones\n",
    "Starting with Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(x_train_prepared, x_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85593019.11023888"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "x_train_predictions = lr_model.predict(x_train_prepared)\n",
    "lr_mse = mean_squared_error(x_train_labels, x_train_predictions)\n",
    "lr_rmse = np.sqrt(lr_mse)\n",
    "lr_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32317472.289727237"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(x_train_prepared, x_train_labels)\n",
    "\n",
    "predictions = rf_model.predict(x_train_prepared)\n",
    "forest_mse = mean_squared_error(x_train_labels, predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [87023153.76917268 91836290.57052778 94762944.79910764 83947501.87149791\n",
      " 79069342.69100092 99981530.13325717 69268789.7863695  83996277.12427057\n",
      " 88549997.20720717 80317960.33494434]\n",
      "Mean: 85875378.82873558\n",
      "Standard deviation: 8259596.441139532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lin_scores = cross_val_score(lr_model, x_train_prepared, x_train_labels,scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_features': [1, 2, 3],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [1, 2, 3],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [{'n_estimators': [3, 10, 30], 'max_features': [1, 2, 3]},{'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [1, 2, 3]},]\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,scoring='neg_mean_squared_error',return_train_score=True)\n",
    "grid_search.fit(x_train_prepared, x_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 2, 'n_estimators': 10}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37255723.74151581"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = x_train_og.drop(\"revenue\", axis=1)\n",
    "y_test = x_train_og[\"revenue\"].copy()\n",
    "X_test_prepared = data_cols_pipeline.transform(X_test)\n",
    "\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/test_transform_predict.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(final_model, '../models/test_boxoffice_model.joblib', compress=6)\n",
    "dump(data_cols_pipeline, '../models/test_transform_predict.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Present your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch, monitor and maintain your system\n",
    "When launching our data model we need to change our input data with live production data from the housing market.\n",
    "While transfering to production data we should also have unit tests in place to make sure things are behaving as expected.\n",
    "\n",
    "We need to monitor the performance of our model and cause events/triggers if the performance is low. We also need to monitor the data input; if the input data isnt as expected it will cause problems with our model. Further as the data evolves, we need to monitor if we need to update our model. The model can become stale as the data input evolves.\n",
    "\n",
    "Even though we are going to monitor the input data and performance, we should regardless retrain our models on a regular basis on fresh input data. This will be an automatically scheduled job that runs every so often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAT158",
   "language": "python",
   "name": "dat158"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
