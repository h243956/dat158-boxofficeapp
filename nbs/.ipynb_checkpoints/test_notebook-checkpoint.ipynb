{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame the problem\n",
    "Normally people can get the value of their house by contacting a housing agency, and or by looking at house prices in their area. In this notebook we will use historical data to predict housing prices in California. The historical data stems from a dataset from 1997 containing housing prices in California. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data\n",
    "The dataset is given as part of an exercise in the book \"Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow concepts, tools, and techniques to build intelligent systems\", 2019. The dataset is downloaded as a .tgz file through github which contains the dataset in a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     3000 non-null   int64  \n",
      " 1   belongs_to_collection  604 non-null    object \n",
      " 2   budget                 3000 non-null   int64  \n",
      " 3   genres                 2993 non-null   object \n",
      " 4   homepage               946 non-null    object \n",
      " 5   imdb_id                3000 non-null   object \n",
      " 6   original_language      3000 non-null   object \n",
      " 7   original_title         3000 non-null   object \n",
      " 8   overview               2992 non-null   object \n",
      " 9   popularity             3000 non-null   float64\n",
      " 10  poster_path            2999 non-null   object \n",
      " 11  production_companies   2844 non-null   object \n",
      " 12  production_countries   2945 non-null   object \n",
      " 13  release_date           3000 non-null   object \n",
      " 14  runtime                2998 non-null   float64\n",
      " 15  spoken_languages       2980 non-null   object \n",
      " 16  status                 3000 non-null   object \n",
      " 17  tagline                2403 non-null   object \n",
      " 18  title                  3000 non-null   object \n",
      " 19  Keywords               2724 non-null   object \n",
      " 20  cast                   2987 non-null   object \n",
      " 21  crew                   2984 non-null   object \n",
      " 22  revenue                3000 non-null   int64  \n",
      "dtypes: float64(2), int64(3), object(18)\n",
      "memory usage: 539.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "                   \n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data to gain insight\n",
    "Lets start off with getting an overview of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_og = test\n",
    "x_train_og = train\n",
    "\n",
    "x_train = x_train_og.drop(\"revenue\", axis=1)\n",
    "x_train_labels = x_train_og[\"revenue\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/kenne/DAT158ML/ML_2/boxofficeapp/localpackages\n",
      "Installing collected packages: localpackages\n",
      "  Attempting uninstall: localpackages\n",
      "    Found existing installation: localpackages 0.1\n",
      "    Uninstalling localpackages-0.1:\n",
      "      Successfully uninstalled localpackages-0.1\n",
      "  Running setup.py develop for localpackages\n",
      "Successfully installed localpackages\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9761b0cc5183>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m data_cols_pipeline = make_pipeline(\n\u001b[0;32m     11\u001b[0m     \u001b[0mSelectColumnsTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mSimpleImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"median\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mSimpleImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"median\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "!{sys.executable} -m pip install -e ../localpackages\n",
    "from localpackages.custom_transformers.custom_transformers import SelectColumnsTransformer\n",
    "                \n",
    "columns = [\"id\", \"budget\", \"popularity\", \"runtime\"]\n",
    "\n",
    "data_cols_pipeline = make_pipeline(\n",
    "    SelectColumnsTransformer(columns),   \n",
    "    SimpleImputer(missing_values=np.nan, strategy=\"median\"),\n",
    "    SimpleImputer(missing_values=0, strategy=\"median\")\n",
    ")\n",
    "\n",
    "#preprocessing_features = DataFrameFeatureUnion([data_cols_pipeline, nullvalues_pipline])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train=preprocessing_features.fit_transform(x_train)\n",
    "x_train_prepared=data_cols_pipeline.fit_transform(x_train)\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore different models and short-list the best ones\n",
    "Starting with Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(x_train_prepared, x_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "x_train_predictions = lr_model.predict(x_train_prepared)\n",
    "lr_mse = mean_squared_error(x_train_labels, x_train_predictions)\n",
    "lr_rmse = np.sqrt(lr_mse)\n",
    "lr_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(x_train_prepared, x_train_labels)\n",
    "\n",
    "predictions = rf_model.predict(x_train_prepared)\n",
    "forest_mse = mean_squared_error(x_train_labels, predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lin_scores = cross_val_score(lr_model, x_train_prepared, x_train_labels,scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [{'n_estimators': [3, 10, 30], 'max_features': [1, 2, 3]},{'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [1, 2, 3]},]\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,scoring='neg_mean_squared_error',return_train_score=True)\n",
    "grid_search.fit(x_train_prepared, x_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = x_train_og.drop(\"revenue\", axis=1)\n",
    "y_test = x_train_og[\"revenue\"].copy()\n",
    "X_test_prepared = data_cols_pipeline.transform(X_test)\n",
    "\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(final_model, '../models/test_boxoffice_model.joblib', compress=6)\n",
    "dump(data_cols_pipeline, '../models/test_transform_predict.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Present your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch, monitor and maintain your system\n",
    "When launching our data model we need to change our input data with live production data from the housing market.\n",
    "While transfering to production data we should also have unit tests in place to make sure things are behaving as expected.\n",
    "\n",
    "We need to monitor the performance of our model and cause events/triggers if the performance is low. We also need to monitor the data input; if the input data isnt as expected it will cause problems with our model. Further as the data evolves, we need to monitor if we need to update our model. The model can become stale as the data input evolves.\n",
    "\n",
    "Even though we are going to monitor the input data and performance, we should regardless retrain our models on a regular basis on fresh input data. This will be an automatically scheduled job that runs every so often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAT158",
   "language": "python",
   "name": "dat158"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
